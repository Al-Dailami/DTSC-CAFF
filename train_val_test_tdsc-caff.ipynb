{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from eicu_reader import eICUReader\n",
    "from mimic_reader import MIMICReader\n",
    "\n",
    "from torch.optim import Adam\n",
    "from dtsc_caff_model import TempSepConv_CAFF\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['dataset'] = 'eICU' #'MIMIC'\n",
    "config['task'] = 'LoS' # 'mortality'\n",
    "config['diagnosis_size'] = 64\n",
    "config['sum_losses'] = False\n",
    "config['loss'] = 'msle'\n",
    "config['last_linear_size'] = 32\n",
    "\n",
    "if config['dataset'] == 'eICU':\n",
    "    config['no_diag'] = False\n",
    "    config['main_dropout_rate'] = 0.45\n",
    "    if config['task'] == 'mortality':\n",
    "        config['n_epochs'] = 6\n",
    "    else:\n",
    "        config['n_epochs'] = 6\n",
    "    config['batch_size'] = 16\n",
    "    config[\"batch_size_test\"] = 8\n",
    "    config['n_layers'] = 11 \n",
    "    config['kernel_size'] = 4\n",
    "    config['temp_kernels'] = [12] * config['n_layers']\n",
    "    config['learning_rate'] = 0.002\n",
    "    config['temp_dropout_rate'] = 0.05\n",
    "\n",
    "elif config['dataset'] == 'MIMIC':\n",
    "    config['no_diag'] = True\n",
    "    config['main_dropout_rate'] = 0\n",
    "    config['n_epochs'] = 10 if config['task'] is not 'mortality' else 6\n",
    "    config['batch_size'] = 8\n",
    "    config['batch_size_test'] = 8 \n",
    "    config['n_layers'] = 8\n",
    "    config['kernel_size'] = 5\n",
    "    config['learning_rate'] = 0.002\n",
    "    config['temp_dropout_rate'] = 0.05\n",
    "    config['temp_kernels'] = [11] * config['n_layers']\n",
    "\n",
    "config['model_ckpt_path'] = './mdl_checkpoints/'\n",
    "\n",
    "config['mdl_name'] = 'DTSC-CAFF'\n",
    "config['window'] = 335 # max 15 days prediction window for LoS prediction\n",
    "config['L2_regularisation'] = 0.0001\n",
    "config['sum_losses'] = True\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# get datareader\n",
    "if config['dataset'] == 'MIMIC':\n",
    "    datareader = MIMICReader\n",
    "    data_path = \"./data/MIMIC_data/\"\n",
    "else:\n",
    "    datareader = eICUReader\n",
    "    data_path = \"./data/eICU_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa42f7c",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aac5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datareader = datareader(data_path + 'train', max_len=config['window'], device=device)\n",
    "val_datareader = datareader(data_path + 'val', max_len= config['window'], device=device)\n",
    "test_datareader = datareader(data_path + 'test', max_len=config['window'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d016c",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e50cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TempSepConv_CAFF(config=config,\n",
    "                                   no_ts_features=train_datareader.no_ts_features,\n",
    "                                   no_daig_features=train_datareader.no_daig_features,\n",
    "                                   no_flat_features=train_datareader.no_flat_features).to(device=device)\n",
    "optimiser = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['L2_regularisation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca746bb9",
   "metadata": {},
   "source": [
    "### Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBins:\n",
    "    inf = 1e18\n",
    "    bins = [(-inf, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 14), (14, +inf)]\n",
    "    nbins = len(bins)\n",
    "\n",
    "def get_bin_custom(x, nbins, one_hot=False):\n",
    "    for i in range(nbins):\n",
    "        a = CustomBins.bins[i][0]\n",
    "        b = CustomBins.bins[i][1]\n",
    "        if a <= x < b:\n",
    "            if one_hot:\n",
    "                onehot = np.zeros((CustomBins.nbins,))\n",
    "                onehot[i] = 1\n",
    "                return onehot\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(4/24, y_true))) * 100  # this stops the mape being a stupidly large value when y_true happens to be very small\n",
    "\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    return np.mean(np.square(np.log(y_true/y_pred)))\n",
    "\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    # mean_square_log_error = np.mean(np.square(np.log(y_true/y_pred)))\n",
    "    square_error = np.square((np.log(y_true + 1) - np.log(y_pred + 1)))\n",
    "    mean_square_log_error = np.mean(square_error)\n",
    "    rmsle_loss = np.sqrt(mean_square_log_error)\n",
    "    return rmsle_loss\n",
    "\n",
    "def print_metrics_regression(y_true, predictions, verbose=1):\n",
    "    print('==> Length of Stay:')\n",
    "    y_true_bins = [get_bin_custom(x, CustomBins.nbins) for x in y_true]\n",
    "    prediction_bins = [get_bin_custom(x, CustomBins.nbins) for x in predictions]\n",
    "    cf = metrics.confusion_matrix(y_true_bins, prediction_bins)\n",
    "    if verbose:\n",
    "        print('Custom bins confusion matrix:')\n",
    "        print(cf)\n",
    "\n",
    "    kappa = metrics.cohen_kappa_score(y_true_bins, prediction_bins, weights='linear')\n",
    "    mad = metrics.mean_absolute_error(y_true, predictions)\n",
    "    mse = metrics.mean_squared_error(y_true, predictions)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_true, predictions))\n",
    "    mape = mean_absolute_percentage_error(y_true, predictions)\n",
    "    msle = mean_squared_logarithmic_error(y_true, predictions)\n",
    "    rmsle = root_mean_squared_logarithmic_error(y_true, predictions)\n",
    "    r2 = metrics.r2_score(y_true, predictions)\n",
    "\n",
    "    if verbose:\n",
    "        print('Mean absolute deviation (MAD) = {}'.format(mad))\n",
    "        print('Mean squared error (MSE) = {}'.format(mse))\n",
    "        print('Root Mean squared error (RMSE) = {}'.format(rmse)) # RMSE\n",
    "        print('Mean absolute percentage error (MAPE) = {}'.format(mape))\n",
    "        print('Mean squared logarithmic error (MSLE) = {}'.format(msle))\n",
    "        print('Root Mean squared logarithmic error (RMSLE) = {}'.format(rmsle)) # RMSLE\n",
    "        print('R^2 Score = {}'.format(r2))\n",
    "        print('Cohen kappa score = {}'.format(kappa))\n",
    "\n",
    "    return [mad, mse, rmse, mape, msle, rmsle, r2, kappa]\n",
    "\n",
    "def print_metrics_mortality(y_true, prediction_probs, verbose=1):\n",
    "    print('==> Mortality:')\n",
    "    prediction_probs = np.array(prediction_probs)\n",
    "    prediction_probs = np.transpose(np.append([1 - prediction_probs], [prediction_probs], axis=0))\n",
    "    predictions = prediction_probs.argmax(axis=1)\n",
    "    cf = metrics.confusion_matrix(y_true, predictions, labels=range(2))\n",
    "    \n",
    "    if verbose:\n",
    "        print('Confusion matrix:')\n",
    "        print(cf)\n",
    "    cf = cf.astype(np.float32)\n",
    "\n",
    "    acc = (cf[0][0] + cf[1][1]) / np.sum(cf)\n",
    "    prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n",
    "    prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
    "    rec0 = cf[0][0] / (cf[0][0] + cf[0][1])\n",
    "    rec1 = cf[1][1] / (cf[1][1] + cf[1][0])\n",
    "\n",
    "    auroc = metrics.roc_auc_score(y_true, prediction_probs[:, 1])\n",
    "    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, prediction_probs[:, 1])\n",
    "    auprc = metrics.auc(recalls, precisions)\n",
    "    f1macro = metrics.f1_score(y_true, predictions, average='macro')\n",
    "\n",
    "    results = {'Accuracy': acc, 'Precision Survived': prec0, 'Precision Died': prec1, 'Recall Survived': rec0,\n",
    "               'Recall Died': rec1, 'Area Under the Receiver Operating Characteristic curve (AUROC)': auroc,\n",
    "               'Area Under the Precision Recall curve (AUPRC)': auprc, 'F1 score (macro averaged)': f1macro}\n",
    "    if verbose:\n",
    "        for key in results:\n",
    "            print('{} = {}'.format(key, results[key]))\n",
    "\n",
    "    return [acc, prec0, prec1, rec0, rec1, auroc, auprc, f1macro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ff30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_padding(y, mask, device):\n",
    "    \"\"\"\n",
    "        Filters out padding from tensor of predictions or labels\n",
    "\n",
    "        Args:\n",
    "            y: tensor of los predictions or labels\n",
    "            mask (bool_type): tensor showing which values are padding (0) and which are data (1)\n",
    "    \"\"\"\n",
    "    \n",
    "    y = y.where(mask, torch.tensor(float('nan')).to(device=device)).flatten().detach().cpu().numpy()\n",
    "    y = y[~np.isnan(y)]\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13b33b",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e874a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_train_batches = len(train_datareader.patients) // config['batch_size']\n",
    "checkpoint_counter = 0\n",
    "no_train_batches = len(train_datareader.patients) // config['batch_size']\n",
    "n_epochs = config['n_epochs']\n",
    "max_auroc = 0\n",
    "max_auprc = 0\n",
    "max_f1macro = 0\n",
    "max_msle = 100\n",
    "max_r2 = 0\n",
    "max_kapa = 0\n",
    "mort_pred_time=18\n",
    "best=True\n",
    "file_name_best = '{}/{}_{}_Best.pth'.format(config['model_ckpt_path'], config['dataset'], config['task'])\n",
    "file_name_last = '{}/{}_{}_Last.pth'.format(config['model_ckpt_path'], config['dataset'], config['task'])\n",
    "\n",
    "remove_padding = lambda y, mask: _remove_padding(y, mask, device=device)\n",
    "\n",
    "bool_type = torch.cuda.BoolTensor if device == torch.device('cuda:3') else torch.BoolTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a646144",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train() \n",
    "    train_batches = train_datareader.batch_gen(batch_size=config['batch_size'])\n",
    "    train_loss = []\n",
    "    train_y_hat_los = np.array([])\n",
    "    train_y_los = np.array([])\n",
    "    train_y_hat_mort = np.array([])\n",
    "    train_y_mort = np.array([])\n",
    "    print('Train Epoch#{}'.format(epoch))\n",
    "    for batch_idx, batch in enumerate(train_batches):\n",
    "        if batch[0].size(0) <= 1:\n",
    "            continue\n",
    "\n",
    "        # unpack batch\n",
    "        if config['dataset'] == 'MIMIC':\n",
    "            padded, mask, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "            diagnoses = None\n",
    "        else:\n",
    "            padded, mask, diagnoses, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        y_hat_los, y_hat_mort, w1, w2 = model(padded, diagnoses, flat)\n",
    "\n",
    "\n",
    "        loss = model.loss(y_hat_los, y_hat_mort, los_labels, mort_labels, mask, seq_lengths, device, \n",
    "                          config['sum_losses'], config['loss'])\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Loss: {} - batch: {} / Num Batches: {}'.format(loss, batch_idx, no_train_batches))\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if config['task'] in ('LoS'):\n",
    "            train_y_hat_los = np.append(train_y_hat_los, remove_padding(y_hat_los, mask.type(bool_type)))\n",
    "            train_y_los = np.append(train_y_los, remove_padding(los_labels, mask.type(bool_type)))\n",
    "            # print('  train_y_hat_los.shape: ==========>',train_y_hat_los.shape)\n",
    "            # print('  train_y_los.shape: ==========>',train_y_los.shape)\n",
    "        if config['task'] in ('mortality') and mort_labels.shape[1] >= mort_pred_time:\n",
    "            train_y_hat_mort = np.append(train_y_hat_mort,\n",
    "                                         remove_padding(y_hat_mort[:, mort_pred_time],\n",
    "                                                             mask.type(bool_type)[:, mort_pred_time]))\n",
    "            train_y_mort = np.append(train_y_mort, remove_padding(mort_labels[:, mort_pred_time],\n",
    "                                                                       mask.type(bool_type)[:, mort_pred_time]))\n",
    "\n",
    "    print('Train Metrics:')\n",
    "    mean_train_loss = sum(train_loss) / len(train_loss)\n",
    "    if config['task'] in ('LoS'):\n",
    "        los_metrics_list = print_metrics_regression(train_y_los, train_y_hat_los) \n",
    "\n",
    "    if config['task'] in ('mortality'):\n",
    "        mort_metrics_list = print_metrics_mortality(train_y_mort, train_y_hat_mort)\n",
    "\n",
    "    print('Epoch: {} | Train Loss: {:3.4f}'.format(epoch, mean_train_loss))\n",
    "    \n",
    "    ########################################### Validation #########################################    \n",
    "    \n",
    "    model.eval()\n",
    "    val_batches = val_datareader.batch_gen(batch_size=config['batch_size_test'])\n",
    "    val_loss = []\n",
    "    val_y_hat_los = np.array([])\n",
    "    val_y_los = np.array([])\n",
    "    val_y_hat_mort = np.array([])\n",
    "    val_y_mort = np.array([])\n",
    "    print('Validation Epoch#{}'.format(epoch))\n",
    "    for batch in val_batches:\n",
    "        if batch[0].size(0) <= 1:\n",
    "            continue\n",
    "\n",
    "        if config['dataset'] == 'MIMIC':\n",
    "            padded, mask, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "            diagnoses = None\n",
    "        else:\n",
    "            padded, mask, diagnoses, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "\n",
    "        y_hat_los, y_hat_mort, w1, w2 = model(padded, diagnoses, flat)\n",
    "        \n",
    "        loss = model.loss(y_hat_los, y_hat_mort, los_labels, mort_labels, mask, seq_lengths, device, \n",
    "                          config['sum_losses'], config['loss'])\n",
    "        val_loss.append(loss.item())  \n",
    "\n",
    "        if config['task'] == 'LoS':\n",
    "            val_y_hat_los = np.append(val_y_hat_los,\n",
    "                                        remove_padding(y_hat_los, mask.type(bool_type)))\n",
    "            val_y_los = np.append(val_y_los, remove_padding(los_labels, mask.type(bool_type)))\n",
    "        if config['task'] == 'mortality' and mort_labels.shape[1] >= mort_pred_time:\n",
    "            val_y_hat_mort = np.append(val_y_hat_mort,\n",
    "                                         remove_padding(y_hat_mort[:, mort_pred_time],\n",
    "                                                             mask.type(bool_type)[:, mort_pred_time]))\n",
    "            val_y_mort = np.append(val_y_mort, remove_padding(mort_labels[:, mort_pred_time],\n",
    "                                                                   mask.type(bool_type)[:, mort_pred_time]))\n",
    "\n",
    "    print('Validation Metrics:')\n",
    "    mean_val_loss = sum(val_loss) / len(val_loss)\n",
    "    \n",
    "    print('Epoch: {} | Validation Loss: {:3.4f}'.format(epoch, mean_val_loss))\n",
    "    \n",
    "    if config['task'] == 'LoS':\n",
    "        los_metrics_list = print_metrics_regression(val_y_los, val_y_hat_los) \n",
    "        ##########################Saving Model#####################\n",
    "        cur_msle = los_metrics_list[4]\n",
    "        cur_r2 = los_metrics_list[6]\n",
    "        cur_kapa = los_metrics_list[7]\n",
    "        print('cur_msle: ', cur_msle)\n",
    "        print('max_msle: ', max_msle)\n",
    "        if cur_msle < max_msle:\n",
    "            print('\\n------------ Save model checkpoint best ------------\\n')\n",
    "            max_msle = cur_msle\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimiser': optimiser.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(state, file_name_best)\n",
    "            \n",
    "        elif epoch == n_epochs - 1:\n",
    "            print('\\n------------ Save model checkpoint last------------\\n')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimiser': optimiser.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(state, file_name_last)\n",
    "\n",
    "    if config['task'] == 'mortality':\n",
    "        mort_metrics_list = print_metrics_mortality(val_y_mort, val_y_hat_mort)\n",
    "        ##########################Saving Model#####################\n",
    "        cur_auroc = mort_metrics_list[5] #5:'auroc', 6:'auprc', 7:'f1macro'\n",
    "        cur_f1_score = mort_metrics_list[7]\n",
    "\n",
    "        if cur_auroc > max_auroc and config['task'] == 'mortality':\n",
    "            max_auroc = cur_auroc\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimiser': optimiser.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(state, file_name_best)\n",
    "            print('\\n------------ Save model checkpoint best ------------\\n')\n",
    "\n",
    "        elif epoch == n_epochs - 1:\n",
    "            print('\\n------------ Save model checkpoint last------------\\n')\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimiser': optimiser.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(state, file_name_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bec355",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdcafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if best:\n",
    "    ####################Load Best Checkpoint######################\n",
    "    checkpoint = torch.load(file_name_best)\n",
    "    save_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    optimiser.load_state_dict(checkpoint['optimiser'])\n",
    "    ##############################################################           \n",
    "else:\n",
    "    ####################Load Last Checkpoint######################\n",
    "    checkpoint = torch.load(file_name_last)\n",
    "    save_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    optimiser.load_state_dict(checkpoint['optimiser'])\n",
    "    ##############################################################           \n",
    "\n",
    "model.eval()\n",
    "test_batches = test_datareader.batch_gen(batch_size=config['batch_size_test'])\n",
    "test_loss = []\n",
    "test_y_hat_los = np.array([])\n",
    "test_y_los = np.array([])\n",
    "test_y_hat_mort = np.array([])\n",
    "test_y_mort = np.array([])\n",
    "\n",
    "for batch in test_batches:\n",
    "    if batch[0].size(0) <= 1:\n",
    "        continue\n",
    "\n",
    "    if config['dataset'] == 'MIMIC':\n",
    "        padded, mask, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "        diagnoses = None\n",
    "    else:\n",
    "        padded, mask, diagnoses, flat, los_labels, mort_labels, seq_lengths = batch\n",
    "\n",
    "    y_hat_los, y_hat_mort, w1, w2 = model(padded, diagnoses, flat)\n",
    "    loss = model.loss(y_hat_los, y_hat_mort, los_labels, mort_labels, mask, seq_lengths, device,\n",
    "                           config['sum_losses'], config['loss'])\n",
    "    test_loss.append(loss.item()) \n",
    "\n",
    "    if config['task'] == 'LoS':\n",
    "        test_y_hat_los = np.append(test_y_hat_los,\n",
    "                                  remove_padding(y_hat_los, mask.type(bool_type)))\n",
    "        test_y_los = np.append(test_y_los, remove_padding(los_labels, mask.type(bool_type)))\n",
    "    if config['task'] == 'mortality' and mort_labels.shape[1] >= mort_pred_time:\n",
    "        test_y_hat_mort = np.append(test_y_hat_mort,\n",
    "                                   remove_padding(y_hat_mort[:, mort_pred_time],\n",
    "                                                       mask.type(bool_type)[:, mort_pred_time]))\n",
    "        test_y_mort = np.append(test_y_mort, remove_padding(mort_labels[:, mort_pred_time],\n",
    "                                                                 mask.type(bool_type)[:, mort_pred_time]))\n",
    "\n",
    "print('Test Metrics:')\n",
    "mean_test_loss = sum(test_loss) / len(test_loss)\n",
    "\n",
    "if config['task'] == 'LoS':\n",
    "    print('  ====> test_y_los.shape: ', test_y_los.shape)\n",
    "    print('  ====> test_y_hat_los.shape: ', test_y_hat_los.shape)\n",
    "    los_metrics_list = print_metrics_regression(test_y_los, test_y_hat_los) \n",
    "if config['task'] == 'mortality':\n",
    "    mort_metrics_list = print_metrics_mortality(test_y_mort, test_y_hat_mort)\n",
    "\n",
    "print('Test Loss: {:3.4f}'.format(mean_test_loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
